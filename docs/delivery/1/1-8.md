#### Task 1-8: Implement Load Model (Import) API Command

##### Description

Implements the API command to load/replace the current model with a provided model specification. This corresponds to `action:"update"` (or possibly `"call"`) on `resource:"model"`, with the new model data provided in the message. This feature allows external plugins to programmatically load a saved model or a generated model (in either SageModeler or SD-JSON format), addressing PBI-1 (basic model import) and PBI-5 (SD-JSON import support).

##### Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
| :---- | :---- | :---- | :---- | :---- | :---- |
| 2025-06-22 17:37:00 | Created | N/A | Proposed | Task drafted (PBI-1 & PBI-5) | Chad |
| 2025-06-25 14:10:00 | Status Change | Proposed | Agreed | Task approved by Product Owner | Chad |
| 2025-06-25 14:30:00 | Status Change | Agreed | Done | Implementation, test interface, and verification complete. Model load via test page works; SD-JSON import returns not implemented error as expected. | ai-agent |

##### Requirements

* Recognize a request intended to load a model: likely `action:"update"` with `resource:"model"`. (We could also accept `action:"call", resource:"model"` if design chooses, but per PRD F-01 they phrased "`load model` replaces current model", likely meaning an update semantics.) We'll assume update.  
    
* The `values` should contain the model data to load. Possibly it could have structure like `{ format: "sd-json", model: { ... } }` or could be the model directly. We need to define how plugin should send it. E.g., `values: { format: "sd-json", content: { ... } }` or simply all model fields at top level of values for native format.  
    
  * To design clearly: We can require `values.format` to specify if the given model is in SD-JSON vs native. If not provided, default assume native format.  
  * And `values.model` (or perhaps `values` itself is the model for native). But since `values` is already an object container, we might prefer `values.model` to hold the model object, to avoid confusion with other fields. That is likely: the plugin will send `{ values: { model: {...}, format: "sd-json" } }`.  
  * If format is native, they could either include format:"native" or omit format. Either way, we expect a `model` object inside values.


* Validate input: The `model` data must be present. If missing, error "No model data provided". If format is specified but unsupported, error as in get model.  
    
* The loading process should **replace** the current model completely. That means:  
    
  * Delete all existing nodes and links in SageModeler (GraphStore.deleteAll() can do this, or sequentially remove nodes). GraphStore.deleteAll() likely clears nodes and links arrays and maybe resets any simulation state. Using GraphStore.deleteAll() is ideal to wipe. Confirm it exists: in GraphStore interface, yes `deleteAll(): void`. We'll call that to clear current model.  
      
  * Then add the new model's nodes and links. We can leverage existing importer logic for this. The SageModeler codebase has an Importer class that used GraphStore and took a data object. Specifically, GraphStore has `loadData(data)` which appears to do similar (GraphStore.init uses it for open saved model, likely). Indeed GraphStore has `loadData(data: any): void` and an internal in importer or migrations. This likely calls ImportActions.import and populates nodes, links, etc.  
      
    * Actually from Importer: calling ImportActions.import.trigger will end up in SimulationStore.onImport, GraphStore maybe. But GraphStore likely uses Importer inside loadData: maybe GraphStore.loadData does something like `Importer.importData(data)` to populate GraphStore. Possibly, since GraphStore imports Importer at top.  
    * Possibly GraphStore.loadData simply does: `ImportActions.import.trigger(data); importer.importNodes(data.nodes); importer.importLinks(data.links); ...` and sets filename. Yes, from Importer.importData snippet, it calls ImportActions.import, then importer.importNodes, importLinks, etc. So GraphStore.loadData probably constructs an Importer and uses it to do all at once. It's the method used when loading a new model (e.g. opening a file).  
    * So we should use GraphStore.loadData(newModelData). This is the simplest way to completely replace the model with the given structure (assuming the structure is in SageModeler native JSON format).

    

  * So for native format: we can likely feed it directly into GraphStore.loadData, and it handles wiping and populating. But to be safe, call GraphStore.deleteAll() first to ensure a clean slate, then GraphStore.loadData(data). (GraphStore.loadData might do a deleteAll internally via GraphPrimitive.initCounters or by deleting graphStore content, but we can double-safeguard or check GraphStore.loadData code if possible. It's likely safe to call directly, as it likely deletes existing graph via graphStore.deleteAll() inside or similar. But we may do both: deleteAll then loadData, if loadData doesn't double-add).  
      
    * We should test to confirm whether loadData automatically clears existing model. Actually, the importer calls `GraphPrimitive.initCounters()` and sets new id counters, but might not explicitly delete existing nodes if any. Probably GraphStore.deleteAll is needed or done by ImportActions.import. However, GraphStore waiting until ready and all, I'd do explicit deleteAll then loadData to ensure no residue.

    

  * For SD-JSON format: we need to convert the given SD-JSON into SageModeler's structure before loading. That will be handled by a conversion function (to complement toSdJson). We'll implement `fromSdJson(sdModel)` in PBI-5. So here, if format is sd-json, we'll call something like `const nativeData = fromSdJson(sdData)`. That should produce an object with shape matching SageModeler's expected data (nodes array, links array, etc.). Then we feed that to GraphStore.loadData.


* After load, the current model should now reflect the new model. We should also ensure any necessary re-initialization happens:  
    
  * GraphStore.loadData likely handles establishing new data context in CODAP if any variables present (since it triggers ImportActions which likely calls CodapConnect to set up data table columns). So presumably it covers CODAP integration and simulation store updates (like SimulationStore.onImport merges settings). Yes, SimulationStore.onImport merges simulation settings, so simulation properties are updated too. So using loadData triggers all those store updates.  
  * We might need to update UI by forcing a refresh. GraphStore.loadData probably triggers a graphChanged event at end or so. Actually, Importer triggers ImportActions.import which might notify UI, and GraphStore at the end sets filename and probably calls updateListeners. The exact sequence could be: GraphStore.loadData \-\> migrationUpdate, ImportActions.import.trigger, importNodes/importLinks (which add nodes with skipUndoRedo, so triggers graphChanged events per addition?). Possibly not each addition triggers graphChanged until end. But Importer after adding nodes calls GraphPrimitive.initCounters and GraphStore.setFilename, but I don't see an explicit call to updateListeners in snippet. There is likely one after loading. If not, we might manually call GraphStore.updateListeners(); however, GraphStore.loadData might be enough. We'll trust it for now.


* Construct response: `success:true`. We might not need to send any specific data, because presumably the plugin already has the model data they gave. Maybe just confirm `{"message":"Model loaded"}` or we can send back the model or its name. It's optional. Possibly send the count of nodes/links loaded or an acknowledgement. Not strictly necessary, but could be nice: e.g., `data: { nodeCount: N, linkCount: M }`. However, to keep consistent with others, perhaps minimal success response (or even data:{}). We'll include a simple count or acknowledge to make use of data field.  
    
* Error handling: If the provided model data is malformed (e.g., missing required structure), `GraphStore.loadData` might throw or do weird things. We should try to catch exceptions. For instance, if SD-JSON conversion fails, catch and error out. If the user sends completely invalid JSON, GraphStore.import might break. We can pre-validate the shape minimally:  
    
  * If format is native and the model object doesn't have a `nodes` array or `links` array, maybe invalid. We could rely on try/catch instead of doing manual validation of structure. Because any valid saved model JSON will have `nodes` and `links` at least.  
      
  * If GraphStore.loadData triggers an error, we catch and respond with error (maybe including message "Failed to load model: ..."). In such a case, we also should consider the state: if we had already deleted the old model (and then load fails), we might have wiped out the old model and now left with nothing. That is a tricky scenario – maybe we should load into a fresh state first then swap? But implementing that would mean doing deep copy etc., which is complex. Alternatively, to avoid leaving an empty state on failure, we could not call deleteAll until after conversion and basic validation. Perhaps:  
      
    * Convert input to native format object (if needed).  
    * Validate that object has at least some structure (like nodes array). If that fails, abort before touching current model.  
    * Once the object seems fine, proceed to deleteAll and loadData.

    

  * That way, if conversion fails, we haven't erased the model. We'll just error and keep current model unchanged.  
      
  * If conversion passes but GraphStore.loadData somehow fails mid-way, partial changes might occur. GraphStore.loadData likely does all or nothing (calls import which triggers adding multiple nodes/links). If an error occurs mid-import, the GraphStore might have some nodes added and some not. That would leave model in a potentially inconsistent partially loaded state. This is an edge case likely only if data is malformed (e.g., link references a node that doesn't exist in given nodes list causing an error). We can attempt to detect such issues (like ensure each link's endpoints exist in nodes list in the input). But to keep it simpler, we'll assume well-formed input (since if plugin is providing model, they presumably have valid data). For safety, we can implement a basic check for link references:  
      
    * For each link in input, check that source and target match some node id in nodes list. If any mismatch, return error "Invalid link references". That could catch some serious malformations.

    

  * If a failure were to happen after partial import, recovering original model is complex, so we likely won't attempt automatic rollback. We'll just notify error. That scenario should be rare given a properly constructed input. We'll note that in dev guidelines for caution.

##### Implementation Plan

1. On `action:"update", resource:"model"` message, call `handleLoadModel(message)`.  
     
2. Extract `format = message.values?.format?.toLowerCase() || "native"`.  
     
3. Extract `modelData = message.values?.model` (assuming the payload uses a nested `model` field). If the convention is different (maybe the message might just include the model directly in values without a wrapper), we need to decide. But using a wrapper `model` is clearer. We'll enforce that in documentation. If `modelData` is undefined, error "No model provided".  
     
4. If format is unrecognized (not "native" or "sd-json"), respond error.  
     
5. If format is "sd-json":  
     
   * The `modelData` is presumably an object in SD-JSON structure. We need to convert it.  
   * Call `const nativeModel = fromSdJson(modelData)` (to be implemented in Task 5-2).  
   * If conversion throws or returns null (meaning it encountered unsupported constructs it cannot handle), decide: the conversion function likely will handle unsupported flows by ignoring and warning (per PRD). So it shouldn't fail entirely unless input missing critical parts. We can wrap in try/catch to catch any thrown error (like if JSON is outright invalid shape). If error, respond error "Failed to import SD-JSON: ..." and abort (keeping old model since not deleted yet).  
   * If conversion succeeds, proceed with `modelToLoad = nativeModel`.  
   * Note: conversion might produce warnings (like ignoring flows). We might want to pass those out. Possibly could include them in response data as e.g. { warnings: \[...\] }. But requirement didn't explicitly ask to return warnings, just to warn internally. Maybe we can log them or include in debug log rather than in API response, to avoid complicating API. We'll skip including warnings in response (or maybe include in a success response data: { importedWithWarnings: true } if any, but not necessary). Possibly log to console if debug.

   

6. If format is "native":  
     
   * The `modelData` should already be in SageModeler's format (i.e., an object with fields like version, nodes, links, settings, etc.). We'll treat it as `modelToLoad = modelData`.  
   * Basic validation: ensure `modelToLoad.nodes` is an array and `modelToLoad.links` is an array. If not, error "Model format not recognized".  
   * (We might also ensure version field or others, but not necessary; older version data still should load via migrations, as migrationUpdate will handle inside Importer).  
   * Possibly ensure modelData is an object (typeof object). If it's e.g. a string (someone accidentally passed a JSON string instead of object), we could attempt JSON.parse it. Actually, if plugin mistakenly sent a JSON string in the message, we might handle it: since the message goes through postMessage, if they constructed it as an object with a property that is a string, it will come as string. We can attempt: if `typeof modelData === "string"`, try `modelToLoad = JSON.parse(modelData)`. If that fails (invalid JSON), error. This way we accept either an actual object or a JSON string of the model. Good robustness.

   

7. At this point, we have `modelToLoad` in native format object and presumably valid structure.  
     
   * (Optional: verify link references integrity: gather all node ids from modelToLoad.nodes (some property like node.id or node.key depending on structure; in saved model JSON, each node is an object with a `id` field likely equal to key). Usually in the exported JSON, each node has `key` and maybe id same, not sure. Actually, from GraphStore.serializeGraph code, it collects nodeExports and linkExports, sets node.id \= node.key in import maybe. It's a bit unclear if the JSON uses `id` or `key`. Possibly `id` and `key` might be same or one omitted. Let's quickly see sample: GraphStore.export likely outputs array of nodes where each node is like `{ key: "node1", data: {...}}`. Actually, GraphStore.serializeGraph likely returns an object where `nodes` is list of objects produced by Node.toExport, which might produce an object with `key` and `data`. If so, the `links` are probably similar (each link with key, sourceNode, targetNode, maybe also in data). We'll assume the structure uses `sourceNode` and `targetNode` keys linking by key strings. We'll just trust GraphStore to handle linking by those keys since it uses them).  
   * It's complex to validate thoroughly without hooking into GraphStore internals. We'll skip explicit deep validation to avoid misinterpreting the structure. GraphStore.importNodes followed by importLinks will naturally fail if references are wrong (since importLinks tries to find node by key, if not found that could throw). But let's trust or minimal check: ensure nodes array length \>0 (if not, it's either an empty model or something; empty model might be allowed though). We can allow empty model (just no nodes or links, GraphStore will just have nothing). So that's fine.  
   * So maybe no further validation beyond structure presence.

   

8. Now proceed to apply:  
     
   * **Clear current model**: call `GraphStore.deleteAll()`. This removes all current nodes and links from GraphStore and triggers any necessary cleanup (like clearing selection, etc.).  
   * Then call `GraphStore.loadData(modelToLoad)`. Wrap this in try/catch in case it fails. If it fails, at this point current model is already cleared. We can't fully restore old model easily. We might still send error, but user lost their model. This is unfortunate but an edge-case we accept (and we instruct in documentation to only call with valid models to avoid that scenario). Possibly we can mitigate by doing a dry-run or partial validation before deletion, but that's complex. We'll proceed with this approach.  
   * GraphStore.loadData will internally handle migrating (via migrationUpdate if version differences), and call Importer to create nodes/links, update SimulationStore with settings, etc. After it returns, the new model is loaded and presumably the UI is updated.  
   * If an error thrown in loadData, catch it. The GraphStore might be left half-populated. In that case, we can try to call GraphStore.deleteAll() again to ensure we leave an empty model rather than a half one. Then respond error "Failed to load model". There's no way to automatically bring back old model at this point (unless we had saved it, which is overkill). Document this as caution.

   

9. If loadData succeeded:  
     
   * The new model is now active. Possibly we should set the simulation store's state or run something? Actually, SimulationStore was updated by ImportActions.import triggered in Importer. The simulation settings (like duration, etc.) from the new model's settings should have been applied, and `modelIsRunnable` etc. updated.  
   * If the message had any notion of a name/filename, GraphStore.setFilename might have been called in importData (looking at Importer.importData: it sets filename from data.filename). So if the JSON had a `filename` field, GraphStore now has it as current filename (which might update UI's model name if shown).  
   * All good. Now we send response success. We might include something like `{ nodeCount: X, linkCount: Y }` in data as a quick summary. That could be useful to confirm. We can get X and Y by GraphStore.getNodes().length and GraphStore.getLinks().length now.  
   * Or we just send success with no data. But including counts or the model name (filename if any) could be helpful. We'll include counts.

   

10. Testing after this is needed.

##### Verification

* **Unit Test**:  
    
  * Use a known model JSON (native format) as input in a message. Possibly produce it by using GraphStore.serializeGraph on a small programmatically built model, or use a fixture. Then call handleLoadModel with that. Then:  
      
    * Check response success.  
    * Check that `GraphStore.getNodes()` now matches the nodes from input (same count, and maybe same titles or ids). We can compare the set of node titles or keys to ensure they loaded.  
    * Check `GraphStore.getLinks()` match expected links (count and connectivity).  
    * Possibly check that `SimulationStore.settings` got updated if the model has specific simulation settings (like duration). If accessible, verify one or two key settings (like SimulationStore.settings.duration equals what was in the input data.settings.simulation.duration).  
    * If the input model had a `filename` field, check that `GraphStore.filename` or some property is set (GraphStore.setFilename likely stores in `graphStore.filename`). If accessible (GraphStore.filename might be a property), verify it's set to the input's filename. Not critical but nice.

    

  * Test with an SD-JSON input (once conversion is implemented in Task 5-2). Construct a minimal SD-JSON example (like one variable and no links) and ensure after calling load with format:"sd-json", the model in GraphStore has that variable as a node. This would test the conversion as well. If conversion not done yet in timeline, that test would be done later.  
      
  * Test error scenario: call load with malformed data:  
      
    * e.g., format:"native" but model missing nodes array. GraphStore.loadData might throw. Our code should catch and respond error. We can simulate by giving modelData \= {} (no nodes property). See if we get `success:false`. GraphStore might throw an error or do nothing. If it doesn't throw but also doesn't populate anything, we might erroneously respond success. To be safe, our code should check if modelToLoad.nodes is array. So let's do: if not array, error out before calling loadData. So test sending {} yields error and old model remains.  
    * Also test unknown format: e.g., format:"xyz", expecting error.  
    * Maybe test sending a JSON string instead of object: values.model \= JSON.stringify(modelObj). Our code will attempt JSON.parse and then proceed. Ensure it succeeds and loads (so we accept string inputs).


* **Integration Test**:  
    
  * Use plugin to send a load model command with a known model (maybe one saved from SageModeler or generated by an AI). Then:  
      
    * Verify the SageModeler UI updates to show the new model (previous nodes disappear, new nodes appear, etc.).  
    * If possible, verify simulation settings updated (maybe by looking at the simulation controls if accessible).  
    * If an SD-JSON from an AI is loaded, verify that nodes and links appear meaningfully (names, polarities, etc.), even if flows are dropped.  
    * Also verify plugin receives the ack success.  
    * Try an erroneous import to see if SageModeler remains on the old model (like send an incomplete model and expect an error; the UI should ideally still have the original model since we aborted before deletion). But due to our approach, we don't delete until right before load. If conversion fails, we won't delete at all. So original model stays. We can simulate conversion failure by sending some gibberish SD-JSON, see that UI remains same and error returns. (This depends on fromSdJson being robust to error).

##### Files Modified

* `src/code/sage-api.ts` – Implement `handleLoadModel`. Use `GraphStore.deleteAll()` and `GraphStore.loadData()`. Import `PaletteStore` for completeness if needed, but GraphStore.loadData likely doesn't require an explicit palette argument (it uses importer which uses GraphStore and PaletteStore internally). Actually, Importer.importData uses `GraphPrimitive.initCounters` and doesn't take palette in loadData because it sets images via palette id lookups. That suggests palette must be accessible inside importer (it has paletteStore set via constructor), but GraphStore.loadData probably created `new Importer(this, settings, PaletteStore)` inside it. We'll trust it.  
* Need to import `GraphStore` (the instance) if not already in context. (We likely have GraphStore imported or accessible as a singleton in `sage-api.ts` already).  
* Import conversion utility `fromSdJson` from wherever it's defined (post Task 5-2). Or define a placeholder if implementing sequentially (maybe temporarily stub as throwing "Not implemented" for now, then fill in later). But in final answer, we assume it's implemented by Task 5-2 and called here.  
* Possibly import `uuid` if we need to do something with keys (but we might not for load, as all ids come from input; GraphStore will reassign or use those given).  
* No changes expected in GraphStore itself. (We rely on its provided methods). We assume GraphStore is ready (the application must be in a state to allow load – likely yes at any time).